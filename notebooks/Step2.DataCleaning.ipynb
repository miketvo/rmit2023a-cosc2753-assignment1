{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Data Preprocessing\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports and environment setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.visualization import header\n",
    "from utils.visualization import count_zero_vals"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T17:30:09.578493Z",
     "end_time": "2023-04-11T17:30:11.073144Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "\n",
    "As discussed in [Step 1. EDA](./Step1.EDA.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-11T17:30:11.083234Z",
     "end_time": "2023-04-11T17:30:11.109079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_train = pd.read_csv(\"../data/Paitients_Files_Train.csv\")\n",
    "df_test = pd.read_csv(\"../data/Paitients_Files_Test.csv\")\n",
    "\n",
    "# Remove duplications (if exist)\n",
    "df_train.drop_duplicates(inplace=True)\n",
    "df_test.drop_duplicates(inplace=True)\n",
    "\n",
    "# Dropping unused columns\n",
    "df_train = df_train.drop(columns=['ID', 'Insurance'])  # Unused col\n",
    "df_test = df_test.drop(columns=['ID', 'Insurance'])    # Unused col\n",
    "\n",
    "# Remove duplications (if exist). We do this a second time because we just dropped two columns, and more duplications might show up\n",
    "df_train.drop_duplicates(inplace=True)\n",
    "df_test.drop_duplicates(inplace=True)\n",
    "\n",
    "# Fix incorrect column name spelling, because I am very particular about grammar and spelling :)\n",
    "df_train = df_train.rename(columns={\"Sepssis\": \"Sepsis\"})\n",
    "\n",
    "# Remove invalid values\n",
    "df_train['PRG'] = df_train['PRG'].replace(0, df_train['PRG'].mean())\n",
    "df_train['PL'] = df_train['PL'].replace(0, df_train['PL'].mean())\n",
    "df_train['PR'] = df_train['PR'].replace(0, df_train['PR'].mean())\n",
    "df_train['SK'] = df_train['SK'].replace(0, df_train['SK'].mean())\n",
    "df_train['TS'] = df_train['TS'].replace(0, df_train['TS'].mean())\n",
    "df_train['M11'] = df_train['M11'].replace(0, df_train['M11'].mean())\n",
    "df_train['BD2'] = df_train['BD2'].replace(0, df_train['BD2'].mean())\n",
    "\n",
    "# Turn categorical values in the target Sepsis column into numerical values so that our model can work with the data\n",
    "df_train[\"Sepsis\"] = df_train[\"Sepsis\"].map({\"Negative\": 0.0, \"Positive\": 1.0})\n",
    "\n",
    "# Save our newly processed data into separate datasets\n",
    "df_train.to_csv(\"../data/cleaned_train.csv\", index=False)\n",
    "df_test.to_csv(\"../data/cleaned_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "From now on, our model would simply need to load up these two file to have access to preprocessed data:\n",
    "- /data/cleaned_train.csv\n",
    "- /data/cleaned_test.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/cleaned_train.csv\")\n",
    "df_test = pd.read_csv(\"../data/cleaned_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T17:30:11.112064Z",
     "end_time": "2023-04-11T17:30:11.118174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═══════╗\n",
      "║ SHAPE ║\n",
      "╚═══════╝\n",
      "(599, 9)\n",
      "\n",
      "╔═════════════════╗\n",
      "║   NULL COUNT    ║\n",
      "╚═════════════════╝\n",
      "PRG       0\n",
      "PL        0\n",
      "PR        0\n",
      "SK        0\n",
      "TS        0\n",
      "M11       0\n",
      "BD2       0\n",
      "Age       0\n",
      "Sepsis    0\n",
      "dtype: int64\n",
      "\n",
      "╔═════════════════════════════════════╗\n",
      "║          COLUMNS OVERVIEW           ║\n",
      "╚═════════════════════════════════════╝\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 599 entries, 0 to 598\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PRG     599 non-null    float64\n",
      " 1   PL      599 non-null    float64\n",
      " 2   PR      599 non-null    float64\n",
      " 3   SK      599 non-null    float64\n",
      " 4   TS      599 non-null    float64\n",
      " 5   M11     599 non-null    float64\n",
      " 6   BD2     599 non-null    float64\n",
      " 7   Age     599 non-null    int64  \n",
      " 8   Sepsis  599 non-null    float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 42.2 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": "        PRG     PL    PR         SK          TS   M11    BD2  Age  Sepsis\n0  6.000000  148.0  72.0  35.000000   79.460768  33.6  0.627   50     1.0\n1  1.000000   85.0  66.0  29.000000   79.460768  26.6  0.351   31     0.0\n2  8.000000  183.0  64.0  20.562604   79.460768  23.3  0.672   32     1.0\n3  1.000000   89.0  66.0  23.000000   94.000000  28.1  0.167   21     0.0\n4  3.824708  137.0  40.0  35.000000  168.000000  43.1  2.288   33     1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRG</th>\n      <th>PL</th>\n      <th>PR</th>\n      <th>SK</th>\n      <th>TS</th>\n      <th>M11</th>\n      <th>BD2</th>\n      <th>Age</th>\n      <th>Sepsis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.000000</td>\n      <td>148.0</td>\n      <td>72.0</td>\n      <td>35.000000</td>\n      <td>79.460768</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>85.0</td>\n      <td>66.0</td>\n      <td>29.000000</td>\n      <td>79.460768</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.000000</td>\n      <td>183.0</td>\n      <td>64.0</td>\n      <td>20.562604</td>\n      <td>79.460768</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.000000</td>\n      <td>89.0</td>\n      <td>66.0</td>\n      <td>23.000000</td>\n      <td>94.000000</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.824708</td>\n      <td>137.0</td>\n      <td>40.0</td>\n      <td>35.000000</td>\n      <td>168.000000</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{header(9, 'SHAPE')}\\n{df_train.shape}\")\n",
    "print(f\"\\n{header(19, 'NULL COUNT')}\\n{df_train.isna().sum()}\")\n",
    "print(f\"\\n{header(39, 'COLUMNS OVERVIEW')}\")\n",
    "print(df_train.info())\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T17:30:11.120176Z",
     "end_time": "2023-04-11T17:30:11.151216Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═══════╗\n",
      "║ SHAPE ║\n",
      "╚═══════╝\n",
      "(169, 8)\n",
      "\n",
      "╔═════════════════╗\n",
      "║   NULL COUNT    ║\n",
      "╚═════════════════╝\n",
      "PRG    0\n",
      "PL     0\n",
      "PR     0\n",
      "SK     0\n",
      "TS     0\n",
      "M11    0\n",
      "BD2    0\n",
      "Age    0\n",
      "dtype: int64\n",
      "\n",
      "╔═════════════════════════════════════╗\n",
      "║          COLUMNS OVERVIEW           ║\n",
      "╚═════════════════════════════════════╝\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169 entries, 0 to 168\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PRG     169 non-null    int64  \n",
      " 1   PL      169 non-null    int64  \n",
      " 2   PR      169 non-null    int64  \n",
      " 3   SK      169 non-null    int64  \n",
      " 4   TS      169 non-null    int64  \n",
      " 5   M11     169 non-null    float64\n",
      " 6   BD2     169 non-null    float64\n",
      " 7   Age     169 non-null    int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 10.7 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": "        PRG     PL    PR         SK          TS   M11    BD2  Age  Sepsis\n0  6.000000  148.0  72.0  35.000000   79.460768  33.6  0.627   50     1.0\n1  1.000000   85.0  66.0  29.000000   79.460768  26.6  0.351   31     0.0\n2  8.000000  183.0  64.0  20.562604   79.460768  23.3  0.672   32     1.0\n3  1.000000   89.0  66.0  23.000000   94.000000  28.1  0.167   21     0.0\n4  3.824708  137.0  40.0  35.000000  168.000000  43.1  2.288   33     1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRG</th>\n      <th>PL</th>\n      <th>PR</th>\n      <th>SK</th>\n      <th>TS</th>\n      <th>M11</th>\n      <th>BD2</th>\n      <th>Age</th>\n      <th>Sepsis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.000000</td>\n      <td>148.0</td>\n      <td>72.0</td>\n      <td>35.000000</td>\n      <td>79.460768</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>85.0</td>\n      <td>66.0</td>\n      <td>29.000000</td>\n      <td>79.460768</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.000000</td>\n      <td>183.0</td>\n      <td>64.0</td>\n      <td>20.562604</td>\n      <td>79.460768</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.000000</td>\n      <td>89.0</td>\n      <td>66.0</td>\n      <td>23.000000</td>\n      <td>94.000000</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.824708</td>\n      <td>137.0</td>\n      <td>40.0</td>\n      <td>35.000000</td>\n      <td>168.000000</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{header(9, 'SHAPE')}\\n{df_test.shape}\")\n",
    "print(f\"\\n{header(19, 'NULL COUNT')}\\n{df_test.isna().sum()}\")\n",
    "print(f\"\\n{header(39, 'COLUMNS OVERVIEW')}\")\n",
    "print(df_test.info())\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T17:30:11.150215Z",
     "end_time": "2023-04-11T17:30:11.167373Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values count: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Null values count: {df_test.isna().sum().sum() + df_train.isna().sum().sum()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T17:30:11.171682Z",
     "end_time": "2023-04-11T17:30:11.178725Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═════════════════════════════════╗\n",
      "║  TRAIN DATA ZERO VALUES COUNT   ║\n",
      "╚═════════════════════════════════╝\n",
      "               Count     Percentage\n",
      "-----------------------------------\n",
      "PRG                0          0.00%\n",
      "PL                 0          0.00%\n",
      "PR                 0          0.00%\n",
      "SK                 0          0.00%\n",
      "TS                 0          0.00%\n",
      "M11                0          0.00%\n",
      "BD2                0          0.00%\n",
      "Age                0          0.00%\n",
      "\n",
      "╔═════════════════════════════════╗\n",
      "║   TEST DATA ZERO VALUES COUNT   ║\n",
      "╚═════════════════════════════════╝\n",
      "               Count     Percentage\n",
      "-----------------------------------\n",
      "PRG               18         10.65%\n",
      "PL                 0          0.00%\n",
      "PR                 7          4.14%\n",
      "SK                52         30.77%\n",
      "TS                85         50.30%\n",
      "M11                2          1.18%\n",
      "BD2                0          0.00%\n",
      "Age                0          0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lookup_cols = ['PRG', 'PL', 'PR', 'SK', 'TS', 'M11', 'BD2', 'Age']\n",
    "print(f\"{header(35, 'TRAIN DATA ZERO VALUES COUNT')}\\n{count_zero_vals(df_train, lookup_cols)}\")\n",
    "print(f\"{header(35, 'TEST DATA ZERO VALUES COUNT')}\\n{count_zero_vals(df_test, lookup_cols)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T17:30:11.175707Z",
     "end_time": "2023-04-11T17:30:11.230862Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After this step, we are ready to start processing our data and then developing our model(s)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note:** The code in this Notebook has been implemented in [utils.processing.Data](../utils/processing.py) for further use. See its documentation for more details."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
