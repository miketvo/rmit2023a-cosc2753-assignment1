{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4: Model Development\n",
    "\n",
    "---\n",
    "\n",
    "Appropriate machine learning algorithms for classification problems like ours includes:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- k-Nearest Neighbors\n",
    "- Support Vector Machine\n",
    "- Naive Bayes\n",
    "\n",
    "Considering the small number of samples in our dataset, the number of features, the binary nature of our problem, and the assignment constraints, we will develop and pick out the best algorithms among these 4:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Bagged Trees\n",
    "- Random Forest\n",
    "\n",
    "For individual model's performance evaluation, we will be using [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) to measure our models' performance and optimize them. While every sepsis case needs immediate attention, thus every potential sepsis patient needs close monitering, false positive predictions might take medical resources away from patients that might actually need it. In subsequent model development, if we see that recall and precision have different weights in our problem domain, we can switch to [F-beta](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html#:~:text=The%20F-beta%20score%20is,recall%20in%20the%20combined%20score.) instead.\n",
    "\n",
    "To get this performance, we will use K-Fold cross validation.\n",
    "\n",
    "For regularization, we will be using Grid Search method to select and fine tune our hyperparameters.\n",
    "\n",
    "To compare between the different model of different algorithms, we will use both $F_1$ score and [ROC-AUC](https://www.youtube.com/watch?v=4jRBRDbJemM). This will be done after we have developed and picked our best models, one for each of the above 4 algorithms. Skip to [Step 5. Model Selection](Step5.ModelSelection.ipynb) for more details.\n",
    "\n",
    "---\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "1. [Dataset](#data)\n",
    "2. [Logistic Regression](#logistic)\n",
    "3. [Decision Tree](#tree)\n",
    "4. [Bagged Trees](#tree)\n",
    "5. [Random Forest](#forest)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Imports and environment setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:38.130933Z",
     "end_time": "2023-04-11T23:04:38.949604Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will store our developed models and their performance in the following variables:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "clfs = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:38.481228Z",
     "end_time": "2023-04-11T23:04:38.950605Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Splitting<a id=\"data\"></a>\n",
    "\n",
    "For this section, we are using the processed datasets from [Step 3. Data Processing](Step3.DataProcessing.ipynb)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/processed_train.csv\")\n",
    "df_test = pd.read_csv(\"../data/processed_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:38.486516Z",
     "end_time": "2023-04-11T23:04:38.950605Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169 entries, 0 to 168\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PRG     169 non-null    float64\n",
      " 1   PL      169 non-null    float64\n",
      " 2   PR      169 non-null    float64\n",
      " 3   SK      169 non-null    float64\n",
      " 4   TS      169 non-null    float64\n",
      " 5   M11     169 non-null    float64\n",
      " 6   BD2     169 non-null    float64\n",
      " 7   Age     169 non-null    float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 10.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                PRG            PL            PR            SK            TS   \ncount  1.690000e+02  1.690000e+02  1.690000e+02  1.690000e+02  1.690000e+02  \\\nmean   1.156209e-16 -3.310961e-16 -1.734313e-16 -8.146015e-17 -6.832142e-17   \nstd    1.002972e+00  1.002972e+00  1.002972e+00  1.002972e+00  1.002972e+00   \nmin   -1.208521e+00 -3.241433e+00 -4.708929e+00 -1.474053e+00 -9.760584e-01   \n25%   -1.207359e+00 -6.956845e-01  2.720883e-02 -1.474053e+00 -9.760584e-01   \n50%    6.858171e-02 -5.691907e-03  2.302438e-01  5.313517e-01 -9.760584e-01   \n75%    8.739056e-01  6.789913e-01  3.197079e-01  7.425575e-01  9.923200e-01   \nmax    1.772338e+00  2.141800e+00  7.261358e-01  1.015063e+00  1.548606e+00   \n\n                M11           BD2           Age  \ncount  1.690000e+02  1.690000e+02  1.690000e+02  \nmean  -1.072121e-15  5.255494e-17 -1.072121e-15  \nstd    1.002972e+00  1.002972e+00  1.002972e+00  \nmin   -8.063583e+00 -1.980105e+00 -1.245210e+00  \n25%   -2.507388e-01 -7.312326e-01 -8.293165e-01  \n50%    1.268218e-01 -5.861043e-02 -3.491998e-01  \n75%    4.138384e-01  7.819177e-01  9.136708e-01  \nmax    1.469355e+00  2.445566e+00  2.504717e+00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRG</th>\n      <th>PL</th>\n      <th>PR</th>\n      <th>SK</th>\n      <th>TS</th>\n      <th>M11</th>\n      <th>BD2</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.690000e+02</td>\n      <td>1.690000e+02</td>\n      <td>1.690000e+02</td>\n      <td>1.690000e+02</td>\n      <td>1.690000e+02</td>\n      <td>1.690000e+02</td>\n      <td>1.690000e+02</td>\n      <td>1.690000e+02</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.156209e-16</td>\n      <td>-3.310961e-16</td>\n      <td>-1.734313e-16</td>\n      <td>-8.146015e-17</td>\n      <td>-6.832142e-17</td>\n      <td>-1.072121e-15</td>\n      <td>5.255494e-17</td>\n      <td>-1.072121e-15</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.002972e+00</td>\n      <td>1.002972e+00</td>\n      <td>1.002972e+00</td>\n      <td>1.002972e+00</td>\n      <td>1.002972e+00</td>\n      <td>1.002972e+00</td>\n      <td>1.002972e+00</td>\n      <td>1.002972e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.208521e+00</td>\n      <td>-3.241433e+00</td>\n      <td>-4.708929e+00</td>\n      <td>-1.474053e+00</td>\n      <td>-9.760584e-01</td>\n      <td>-8.063583e+00</td>\n      <td>-1.980105e+00</td>\n      <td>-1.245210e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-1.207359e+00</td>\n      <td>-6.956845e-01</td>\n      <td>2.720883e-02</td>\n      <td>-1.474053e+00</td>\n      <td>-9.760584e-01</td>\n      <td>-2.507388e-01</td>\n      <td>-7.312326e-01</td>\n      <td>-8.293165e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>6.858171e-02</td>\n      <td>-5.691907e-03</td>\n      <td>2.302438e-01</td>\n      <td>5.313517e-01</td>\n      <td>-9.760584e-01</td>\n      <td>1.268218e-01</td>\n      <td>-5.861043e-02</td>\n      <td>-3.491998e-01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.739056e-01</td>\n      <td>6.789913e-01</td>\n      <td>3.197079e-01</td>\n      <td>7.425575e-01</td>\n      <td>9.923200e-01</td>\n      <td>4.138384e-01</td>\n      <td>7.819177e-01</td>\n      <td>9.136708e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.772338e+00</td>\n      <td>2.141800e+00</td>\n      <td>7.261358e-01</td>\n      <td>1.015063e+00</td>\n      <td>1.548606e+00</td>\n      <td>1.469355e+00</td>\n      <td>2.445566e+00</td>\n      <td>2.504717e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.info()\n",
    "df_test.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:38.504298Z",
     "end_time": "2023-04-11T23:04:38.962157Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 782 entries, 0 to 781\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PRG     782 non-null    float64\n",
      " 1   PL      782 non-null    float64\n",
      " 2   PR      782 non-null    float64\n",
      " 3   SK      782 non-null    float64\n",
      " 4   TS      782 non-null    float64\n",
      " 5   M11     782 non-null    float64\n",
      " 6   BD2     782 non-null    float64\n",
      " 7   Age     782 non-null    float64\n",
      " 8   Sepsis  782 non-null    float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 55.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "              PRG          PL          PR          SK          TS         M11   \ncount  782.000000  782.000000  782.000000  782.000000  782.000000  782.000000  \\\nmean     0.093303    0.120884    0.053327    0.066275    0.094252    0.079220   \nstd      0.981172    0.991983    1.024143    0.972240    0.993948    0.979384   \nmin     -1.739748   -3.875880   -3.277139   -3.720660   -1.784871   -2.680662   \n25%     -0.756075   -0.554200   -0.471875   -0.524925   -0.325599   -0.588994   \n50%      0.164328    0.120653    0.097826   -0.066467   -0.325599    0.143147   \n75%      0.803661    0.835510    0.787667    0.786756    0.522600    0.726554   \nmax      1.787925    2.066296    2.182884    2.050475    1.652611    2.195947   \n\n              BD2         Age     Sepsis  \ncount  782.000000  782.000000  782.00000  \nmean     0.081804    0.107794    0.50000  \nstd      1.007280    1.002119    0.50032  \nmin     -2.664330   -1.288830    0.00000  \n25%     -0.642949   -0.713537    0.00000  \n50%      0.133515   -0.003753    0.50000  \n75%      0.911406    0.918774    1.00000  \nmax      1.855361    2.256671    1.00000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRG</th>\n      <th>PL</th>\n      <th>PR</th>\n      <th>SK</th>\n      <th>TS</th>\n      <th>M11</th>\n      <th>BD2</th>\n      <th>Age</th>\n      <th>Sepsis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>782.000000</td>\n      <td>782.000000</td>\n      <td>782.000000</td>\n      <td>782.000000</td>\n      <td>782.000000</td>\n      <td>782.000000</td>\n      <td>782.000000</td>\n      <td>782.000000</td>\n      <td>782.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.093303</td>\n      <td>0.120884</td>\n      <td>0.053327</td>\n      <td>0.066275</td>\n      <td>0.094252</td>\n      <td>0.079220</td>\n      <td>0.081804</td>\n      <td>0.107794</td>\n      <td>0.50000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.981172</td>\n      <td>0.991983</td>\n      <td>1.024143</td>\n      <td>0.972240</td>\n      <td>0.993948</td>\n      <td>0.979384</td>\n      <td>1.007280</td>\n      <td>1.002119</td>\n      <td>0.50032</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.739748</td>\n      <td>-3.875880</td>\n      <td>-3.277139</td>\n      <td>-3.720660</td>\n      <td>-1.784871</td>\n      <td>-2.680662</td>\n      <td>-2.664330</td>\n      <td>-1.288830</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.756075</td>\n      <td>-0.554200</td>\n      <td>-0.471875</td>\n      <td>-0.524925</td>\n      <td>-0.325599</td>\n      <td>-0.588994</td>\n      <td>-0.642949</td>\n      <td>-0.713537</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.164328</td>\n      <td>0.120653</td>\n      <td>0.097826</td>\n      <td>-0.066467</td>\n      <td>-0.325599</td>\n      <td>0.143147</td>\n      <td>0.133515</td>\n      <td>-0.003753</td>\n      <td>0.50000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.803661</td>\n      <td>0.835510</td>\n      <td>0.787667</td>\n      <td>0.786756</td>\n      <td>0.522600</td>\n      <td>0.726554</td>\n      <td>0.911406</td>\n      <td>0.918774</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.787925</td>\n      <td>2.066296</td>\n      <td>2.182884</td>\n      <td>2.050475</td>\n      <td>1.652611</td>\n      <td>2.195947</td>\n      <td>1.855361</td>\n      <td>2.256671</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:38.538351Z",
     "end_time": "2023-04-11T23:04:38.963159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (625, 8)\n",
      "train_y shape: (625, 1)\n",
      "val_X shape: (157, 8)\n",
      "val_y shape: (157, 1)\n"
     ]
    }
   ],
   "source": [
    "# Separate our features (X) and target (y)\n",
    "df_X = df_train.drop([\"Sepsis\"], axis=1)\n",
    "df_y = df_train[[\"Sepsis\"]]\n",
    "\n",
    "# Splitting our training data into a train set and a validation set\n",
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "    df_X, df_y,\n",
    "    shuffle=True,\n",
    "    random_state=0,  # Ensure reproducible results\n",
    "    test_size=0.2    # 80% Train - 20% Validation\n",
    ")\n",
    "\n",
    "print(f\"train_X shape: {train_X.shape}\")\n",
    "print(f\"train_y shape: {train_y.shape}\")\n",
    "print(f\"val_X shape: {val_X.shape}\")\n",
    "print(f\"val_y shape: {val_y.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:38.567377Z",
     "end_time": "2023-04-11T23:04:38.963159Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up K-Fold cross validation for our models:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "cv = KFold(\n",
    "    n_splits=4,     # Each fold is 20% of df_X\n",
    "    shuffle=True,\n",
    "    random_state=0  # Reproducible result\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:38.572385Z",
     "end_time": "2023-04-11T23:04:38.963159Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Logistic Regression<a id=\"logistic\"></a>\n",
    "\n",
    "We would develop and evaluate the following models to find the best Logistic Regression candidate for our problem:\n",
    "\n",
    "- Logistic Regression with Linear Features (`clf_logistic[\"linear\"]`);\n",
    "- Logistic Regression with Polynomial Features of degree 2 (`clf_logistic[\"poly2\"]`);\n",
    "- Logistic Regression with Polynomial Features of degree 3 (`clf_logistic[\"poly3\"]`);\n",
    "- Logistic Regression with Polynomial Features of degree 4 (`clf_logistic[\"poly4\"]`).\n",
    "\n",
    "We are experimenting with both $L_1$ (lasso) and $L_2$ (ridge) regularization to find out which method is more appropriate. And although findings in [Step 1. EDA](Step1.EDA.ipynb) suggest that we stop at Polynomial Features of degree 3, we are still experimenting with degree 4 because we introduced regularization into our Logistic Regression model. However, we will not go any higher than degree 4, since it is too computationally expensive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    solver=\"liblinear\",       # Good for our small dataset\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1_000,\n",
    "    random_state=0            # Reproducible result\n",
    ")\n",
    "\n",
    "clfs_logistic = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:38.577118Z",
     "end_time": "2023-04-11T23:04:38.963159Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Hyperparameters\n",
    "\n",
    "- Regularization strength $\\lambda$ (lambda)\n",
    "- Regularization type: $L_1$ or $L_2$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"C\": 1 / np.logspace(-5, 2, num=100),\n",
    "    \"penalty\": [\"l1\", \"l2\"]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:38.581982Z",
     "end_time": "2023-04-11T23:04:38.963159Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Logistic Regression with Linear Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "pred_y = clfs_logistic[\"linear\"].predict(val_X)\n",
    "clfs_logistic[\"linear\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:45:03.542159Z",
     "end_time": "2023-04-11T23:45:05.266054Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8166438146598718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.79      0.86        82\n",
      "         1.0       0.80      0.93      0.86        75\n",
      "\n",
      "    accuracy                           0.86       157\n",
      "   macro avg       0.87      0.86      0.86       157\n",
      "weighted avg       0.87      0.86      0.86       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(grid_clf.best_score_)\n",
    "print(classification_report(val_y, pred_y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:45:06.164682Z",
     "end_time": "2023-04-11T23:45:06.180244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "sns.heatmap(confusion_matrix(val_y, pred_y), annot=True, cmap='Blues', fmt='g', ax=axis)\n",
    "axis.set_xlabel('Predicted Values')\n",
    "axis.set_ylabel('True Values')\n",
    "axis.set_title('Confusion Matrix for Logistic Regression Model')\n",
    "\n",
    "axis.set_xticks([0.5, 1.5])\n",
    "axis.set_xticklabels(['Negative', 'Positive'])\n",
    "axis.set_yticks([0.5, 1.5])\n",
    "axis.set_yticklabels(['Negative', 'Positive'])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"../images/LogisticRegression.png\")\n",
    "print(classification_report(val_y, pred_y))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3. Logistic Regression with Degree 2 Polynomial Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Degree 2 Polynomial Features:\n",
    "poly = PolynomialFeatures(2)\n",
    "train_X_poly2 = poly.fit_transform(train_X)\n",
    "val_X_poly2 = poly.transform(val_X)\n",
    "\n",
    "# We need to scale the data again after transforming it to polynomial features\n",
    "scaler = StandardScaler()\n",
    "train_X_poly2 = scaler.fit_transform(train_X_poly2)\n",
    "val_X_poly2 = scaler.transform(val_X_poly2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:42.805862Z",
     "end_time": "2023-04-11T23:04:42.811435Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X_poly2, train_y.values.ravel())\n",
    "\n",
    "clfs_logistic[\"poly2\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:42.812437Z",
     "end_time": "2023-04-11T23:04:46.726653Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4. Logistic Regression with Degree 3 Polynomial Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Degree 3 Polynomial Features:\n",
    "poly = PolynomialFeatures(3)\n",
    "train_X_poly3 = poly.fit_transform(train_X)\n",
    "val_X_poly3 = poly.transform(val_X)\n",
    "\n",
    "# We need to scale the data again after transforming it to polynomial features\n",
    "scaler = StandardScaler()\n",
    "train_X_poly3 = scaler.fit_transform(train_X_poly3)\n",
    "val_X_poly3 = scaler.transform(val_X_poly3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:46.728652Z",
     "end_time": "2023-04-11T23:04:46.738864Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X_poly3, train_y.values.ravel())\n",
    "\n",
    "clfs_logistic[\"poly3\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:04:46.739864Z",
     "end_time": "2023-04-11T23:06:40.327764Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5. Logistic Regression with Degree 4 Polynomial Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Degree 4 Polynomial Features:\n",
    "poly = PolynomialFeatures(4)\n",
    "train_X_poly4 = poly.fit_transform(train_X)\n",
    "val_X_poly4 = poly.transform(val_X)\n",
    "\n",
    "# We need to scale the data again after transforming it to polynomial features\n",
    "scaler = StandardScaler()\n",
    "train_X_poly4 = scaler.fit_transform(train_X_poly4)\n",
    "val_X_poly4 = scaler.transform(val_X_poly4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:06:40.331764Z",
     "end_time": "2023-04-11T23:06:40.342236Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X_poly4, train_y.values.ravel())\n",
    "\n",
    "clfs_logistic[\"poly4\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:06:40.343236Z",
     "end_time": "2023-04-11T23:07:42.424676Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6. Observation\n",
    "\n",
    "All models seem to have good fit on the problem, however:\n",
    "\n",
    "- $L_1$ (Lasso) Regularization clearly is not a good choice for our problem, as the larger $\\lambda$ (lambda) grows, the worse our models' performance gets, regardless of which degree of polynomial feature it is. This is likely because we have only a few features, and all of them are significant, while Lasso Regularization tends to feature select.\n",
    "- Thus $L_2$ (Ridge) Regularization is more appropriate for our problem.\n",
    "- The best performing model is `clf_logistic4_l2`, in contrary to our hypothesis in [Step 1. EDA](Step1.EDA.ipynb), but this is because we have applied regularization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.8. Best Logistic Regression Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Decision Tree<a id=\"tree\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1. Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": np.arange(2, 300, 50),\n",
    "    \"min_samples_split\": np.arange(2, 50, 5),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:07:42.428189Z",
     "end_time": "2023-04-11T23:07:42.431784Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2. Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=KFold(n_splits=4, random_state=0, shuffle=True),\n             estimator=DecisionTreeClassifier(class_weight='balanced',\n                                              random_state=0),\n             param_grid={'max_depth': array([  2,  52, 102, 152, 202, 252]),\n                         'min_samples_split': array([ 2,  7, 12, 17, 22, 27, 32, 37, 42, 47])},\n             scoring='f1')",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=4, random_state=0, shuffle=True),\n             estimator=DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;,\n                                              random_state=0),\n             param_grid={&#x27;max_depth&#x27;: array([  2,  52, 102, 152, 202, 252]),\n                         &#x27;min_samples_split&#x27;: array([ 2,  7, 12, 17, 22, 27, 32, 37, 42, 47])},\n             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=4, random_state=0, shuffle=True),\n             estimator=DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;,\n                                              random_state=0),\n             param_grid={&#x27;max_depth&#x27;: array([  2,  52, 102, 152, 202, 252]),\n                         &#x27;min_samples_split&#x27;: array([ 2,  7, 12, 17, 22, 27, 32, 37, 42, 47])},\n             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",         # Good for balanced data (we have already up-sampled out data so it is now balanced)\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=0            # Reproducible result\n",
    ")\n",
    "\n",
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X, train_y.values.ravel())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T23:07:42.433293Z",
     "end_time": "2023-04-11T23:07:43.897335Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
