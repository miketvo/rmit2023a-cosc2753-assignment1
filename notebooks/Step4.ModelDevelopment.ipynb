{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4: Model Development\n",
    "\n",
    "---\n",
    "\n",
    "Appropriate machine learning algorithms for classification problems like ours includes:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- k-Nearest Neighbors\n",
    "- Support Vector Machine\n",
    "- Naive Bayes\n",
    "\n",
    "Considering the small number of samples in our dataset, the number of features, the binary nature of our problem, and the assignment constraints, we will develop and pick out the best algorithms among these 4:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Bagged Trees\n",
    "- Random Forest\n",
    "\n",
    "For individual model's performance evaluation, we will be using [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) to measure our models' performance and optimize them. While every sepsis case needs immediate attention, thus every potential sepsis patient needs close monitering, false positive predictions might take medical resources away from patients that might actually need it. In subsequent model development, if we see that recall and precision have different weights in our problem domain, we can switch to [F-beta](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html#:~:text=The%20F-beta%20score%20is,recall%20in%20the%20combined%20score.) instead.\n",
    "\n",
    "To get this performance, we will use K-Fold cross validation.\n",
    "\n",
    "For regularization, we will be using Grid Search method to select and fine tune our hyperparameters.\n",
    "\n",
    "To compare between the different model of different algorithms, we will use both $F_1$ score and [ROC-AUC](https://www.youtube.com/watch?v=4jRBRDbJemM). This will be done after we have developed and picked our best models, one for each of the above 4 algorithms. Skip to [Step 5. Model Selection](Step5.ModelSelection.ipynb) for more details.\n",
    "\n",
    "---\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "1. [Data Splitting](#data)\n",
    "2. [Logistic Regression](#logistic)\n",
    "3. [Decision Tree](#tree)\n",
    "4. [Bagged Trees](#bagged-trees)\n",
    "5. [Random Forest](#forest)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imports and environment setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:11.568003Z",
     "end_time": "2023-04-12T01:00:12.951329Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will store our developed models and their performance in the following variables:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clfs = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:11.928177Z",
     "end_time": "2023-04-12T01:00:12.951329Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Splitting<a id=\"data\"></a>\n",
    "\n",
    "For this section, we are using the processed datasets from [Step 3. Data Processing](Step3.DataProcessing.ipynb)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/processed_train.csv\")\n",
    "df_test = pd.read_csv(\"../data/processed_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:11.932188Z",
     "end_time": "2023-04-12T01:00:12.951329Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.info()\n",
    "df_test.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:11.949050Z",
     "end_time": "2023-04-12T01:00:12.975397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:11.983841Z",
     "end_time": "2023-04-12T01:00:12.975397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separate our features (X) and target (y)\n",
    "df_X = df_train.drop([\"Sepsis\"], axis=1)\n",
    "df_y = df_train[[\"Sepsis\"]]\n",
    "\n",
    "# Splitting our training data into a train set and a validation set\n",
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "    df_X, df_y,\n",
    "    shuffle=True,\n",
    "    random_state=0,  # Ensure reproducible results\n",
    "    test_size=0.2    # 80% Train - 20% Validation\n",
    ")\n",
    "\n",
    "print(f\"train_X shape: {train_X.shape}\")\n",
    "print(f\"train_y shape: {train_y.shape}\")\n",
    "print(f\"val_X shape: {val_X.shape}\")\n",
    "print(f\"val_y shape: {val_y.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:12.013695Z",
     "end_time": "2023-04-12T01:00:13.005467Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up K-Fold cross validation for our models:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv = KFold(\n",
    "    n_splits=4,     # Each fold is 20% of df_X\n",
    "    shuffle=True,\n",
    "    random_state=0  # Reproducible result\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:12.021745Z",
     "end_time": "2023-04-12T01:00:13.005467Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Logistic Regression<a id=\"logistic\"></a>\n",
    "\n",
    "We would develop and evaluate the following models to find the best Logistic Regression candidate for our problem:\n",
    "\n",
    "- Logistic Regression with Linear Features (`clf_logistic[\"linear\"]`);\n",
    "- Logistic Regression with Polynomial Features of degree 2 (`clf_logistic[\"poly2\"]`);\n",
    "- Logistic Regression with Polynomial Features of degree 3 (`clf_logistic[\"poly3\"]`);\n",
    "- Logistic Regression with Polynomial Features of degree 4 (`clf_logistic[\"poly4\"]`).\n",
    "\n",
    "We are experimenting with both $L_1$ (lasso) and $L_2$ (ridge) regularization to find out which method is more appropriate. And although findings in [Step 1. EDA](Step1.EDA.ipynb) suggest that we stop at Polynomial Features of degree 3, we are still experimenting with degree 4 because we introduced regularization into our Logistic Regression model. However, we will not go any higher than degree 4, since it is too computationally expensive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    solver=\"liblinear\",       # Good for our small dataset\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1_000,\n",
    "    random_state=0            # Reproducible result\n",
    ")\n",
    "\n",
    "clfs_logistic = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:12.025259Z",
     "end_time": "2023-04-12T01:00:13.005467Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Hyperparameters\n",
    "\n",
    "- Regularization strength $\\lambda$ (lambda)\n",
    "- Regularization type: $L_1$ or $L_2$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"C\": 1 / np.logspace(-5, 2, num=100),\n",
    "    \"penalty\": [\"l1\", \"l2\"]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:12.031305Z",
     "end_time": "2023-04-12T01:00:13.005467Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Logistic Regression with Linear Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "pred_y = grid_clf.predict(val_X)\n",
    "clfs_logistic[\"linear\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:12.038621Z",
     "end_time": "2023-04-12T01:00:16.180508Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "sns.heatmap(confusion_matrix(val_y, pred_y), annot=True, cmap=\"Blues\", fmt=\"g\", ax=axis)\n",
    "axis.set_xlabel(\"Predicted Values\")\n",
    "axis.set_ylabel(\"True Values\")\n",
    "axis.set_title(\"Logistic Regression - Linear Features\")\n",
    "\n",
    "axis.set_xticks([0.5, 1.5])\n",
    "axis.set_xticklabels([\"Negative\", \"Positive\"])\n",
    "axis.set_yticks([0.5, 1.5])\n",
    "axis.set_yticklabels([\"Negative\", \"Positive\"])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"../images/ModelDev_Logistic1_CM.png\")\n",
    "print(classification_report(val_y, pred_y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:16.180508Z",
     "end_time": "2023-04-12T01:00:16.484008Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3. Logistic Regression with 2nd Order Polynomial Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Degree 2 Polynomial Features:\n",
    "poly = PolynomialFeatures(2)\n",
    "train_X_poly2 = poly.fit_transform(train_X)\n",
    "val_X_poly2 = poly.transform(val_X)\n",
    "\n",
    "# We need to scale the data again after transforming it to polynomial features\n",
    "scaler = StandardScaler()\n",
    "train_X_poly2 = scaler.fit_transform(train_X_poly2)\n",
    "val_X_poly2 = scaler.transform(val_X_poly2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:16.466649Z",
     "end_time": "2023-04-12T01:00:16.484008Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X_poly2, train_y.values.ravel())\n",
    "\n",
    "pred_y = grid_clf.predict(val_X_poly2)\n",
    "clfs_logistic[\"poly2\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:16.474757Z",
     "end_time": "2023-04-12T01:00:20.177954Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "sns.heatmap(confusion_matrix(val_y, pred_y), annot=True, cmap=\"Blues\", fmt=\"g\", ax=axis)\n",
    "axis.set_xlabel(\"Predicted Values\")\n",
    "axis.set_ylabel(\"True Values\")\n",
    "axis.set_title(\"Logistic Regression - 2nd Order Polynomial\")\n",
    "\n",
    "axis.set_xticks([0.5, 1.5])\n",
    "axis.set_xticklabels([\"Negative\", \"Positive\"])\n",
    "axis.set_yticks([0.5, 1.5])\n",
    "axis.set_yticklabels([\"Negative\", \"Positive\"])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"../images/ModelDev_Logistic2_CM.png\")\n",
    "print(classification_report(val_y, pred_y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:20.179991Z",
     "end_time": "2023-04-12T01:00:20.447870Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4. Logistic Regression with 3rd Order Polynomial Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Degree 3 Polynomial Features:\n",
    "poly = PolynomialFeatures(3)\n",
    "train_X_poly3 = poly.fit_transform(train_X)\n",
    "val_X_poly3 = poly.transform(val_X)\n",
    "\n",
    "# We need to scale the data again after transforming it to polynomial features\n",
    "scaler = StandardScaler()\n",
    "train_X_poly3 = scaler.fit_transform(train_X_poly3)\n",
    "val_X_poly3 = scaler.transform(val_X_poly3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:20.419827Z",
     "end_time": "2023-04-12T01:00:20.447870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X_poly3, train_y.values.ravel())\n",
    "\n",
    "pred_y = grid_clf.predict(val_X_poly3)\n",
    "clfs_logistic[\"poly3\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:00:20.430775Z",
     "end_time": "2023-04-12T01:02:01.452150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "sns.heatmap(confusion_matrix(val_y, pred_y), annot=True, cmap=\"Blues\", fmt=\"g\", ax=axis)\n",
    "axis.set_xlabel(\"Predicted Values\")\n",
    "axis.set_ylabel(\"True Values\")\n",
    "axis.set_title(\"Logistic Regression - 3rd Order Polynomial\")\n",
    "\n",
    "axis.set_xticks([0.5, 1.5])\n",
    "axis.set_xticklabels([\"Negative\", \"Positive\"])\n",
    "axis.set_yticks([0.5, 1.5])\n",
    "axis.set_yticklabels([\"Negative\", \"Positive\"])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"../images/ModelDev_Logistic3_CM.png\")\n",
    "print(classification_report(val_y, pred_y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:02:01.461175Z",
     "end_time": "2023-04-12T01:02:01.768443Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5. Logistic Regression with 4th Order Polynomial Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Degree 4 Polynomial Features:\n",
    "poly = PolynomialFeatures(4)\n",
    "train_X_poly4 = poly.fit_transform(train_X)\n",
    "val_X_poly4 = poly.transform(val_X)\n",
    "\n",
    "# We need to scale the data again after transforming it to polynomial features\n",
    "scaler = StandardScaler()\n",
    "train_X_poly4 = scaler.fit_transform(train_X_poly4)\n",
    "val_X_poly4 = scaler.transform(val_X_poly4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:02:01.734437Z",
     "end_time": "2023-04-12T01:02:01.768443Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X_poly4, train_y.values.ravel())\n",
    "\n",
    "pred_y = grid_clf.predict(val_X_poly4)\n",
    "clfs_logistic[\"poly4\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:02:01.751881Z",
     "end_time": "2023-04-12T01:03:02.823050Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "sns.heatmap(confusion_matrix(val_y, pred_y), annot=True, cmap=\"Blues\", fmt=\"g\", ax=axis)\n",
    "axis.set_xlabel(\"Predicted Values\")\n",
    "axis.set_ylabel(\"True Values\")\n",
    "axis.set_title(\"Logistic Regression - 4th Order Polynomial\")\n",
    "\n",
    "axis.set_xticks([0.5, 1.5])\n",
    "axis.set_xticklabels([\"Negative\", \"Positive\"])\n",
    "axis.set_yticks([0.5, 1.5])\n",
    "axis.set_yticklabels([\"Negative\", \"Positive\"])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"../images/ModelDev_Logistic4_CM.png\")\n",
    "print(classification_report(val_y, pred_y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:03:02.827560Z",
     "end_time": "2023-04-12T01:03:03.126249Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6. Observation\n",
    "\n",
    "All models seem to have good fit on the problem, however:\n",
    "\n",
    "- $L_1$ (Lasso) Regularization clearly is not a good choice for our problem, as the larger $\\lambda$ (lambda) grows, the worse our models' performance gets, regardless of which degree of polynomial feature it is. This is likely because we have only a few features, and all of them are significant, while Lasso Regularization tends to feature select.\n",
    "- Thus $L_2$ (Ridge) Regularization is more appropriate for our problem.\n",
    "- The best performing model is `clf_logistic4_l2`, in contrary to our hypothesis in [Step 1. EDA](Step1.EDA.ipynb), but this is because we have applied regularization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.7. Best Logistic Regression Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clfs[\"logistic\"] = clfs_logistic[\"poly4\"].best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:03:03.103750Z",
     "end_time": "2023-04-12T01:03:03.127189Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Decision Tree<a id=\"tree\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1. Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": np.arange(2, 300, 50),\n",
    "    \"min_samples_split\": np.arange(2, 50, 5),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:03:03.110398Z",
     "end_time": "2023-04-12T01:03:03.127189Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2. Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",         # Good for balanced data (we have already up-sampled out data so it is now balanced)\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=0            # Reproducible result\n",
    ")\n",
    "\n",
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "pred_y = grid_clf.predict(val_X)\n",
    "clfs[\"tree\"] = grid_clf.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:03:03.118611Z",
     "end_time": "2023-04-12T01:03:04.651553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "sns.heatmap(confusion_matrix(val_y, pred_y), annot=True, cmap=\"Blues\", fmt=\"g\", ax=axis)\n",
    "axis.set_xlabel(\"Predicted Values\")\n",
    "axis.set_ylabel(\"True Values\")\n",
    "axis.set_title(\"Decision Tree\")\n",
    "\n",
    "axis.set_xticks([0.5, 1.5])\n",
    "axis.set_xticklabels([\"Negative\", \"Positive\"])\n",
    "axis.set_yticks([0.5, 1.5])\n",
    "axis.set_yticklabels([\"Negative\", \"Positive\"])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"../images/ModelDev_Tree_CM.png\")\n",
    "print(classification_report(val_y, pred_y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:03:04.653552Z",
     "end_time": "2023-04-12T01:03:04.926253Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Bagged Trees<a id=\"bagged-trees\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1. Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": np.arange(5, 25, 2),\n",
    "    \"max_samples\": np.arange(0.1, 1.0, 0.1),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:03:04.898058Z",
     "end_time": "2023-04-12T01:03:04.926253Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2. Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(\n",
    "    estimator=clfs[\"tree\"],\n",
    "    random_state=0  # Reproducible result\n",
    ")\n",
    "\n",
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "pred_y = grid_clf.predict(val_X)\n",
    "# clf[\"bagged_trees\"] = grid_clf.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:03:04.903905Z",
     "end_time": "2023-04-12T01:03:19.623260Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "sns.heatmap(confusion_matrix(val_y, pred_y), annot=True, cmap=\"Blues\", fmt=\"g\", ax=axis)\n",
    "axis.set_xlabel(\"Predicted Values\")\n",
    "axis.set_ylabel(\"True Values\")\n",
    "axis.set_title(\"Bagged Trees\")\n",
    "\n",
    "axis.set_xticks([0.5, 1.5])\n",
    "axis.set_xticklabels([\"Negative\", \"Positive\"])\n",
    "axis.set_yticks([0.5, 1.5])\n",
    "axis.set_yticklabels([\"Negative\", \"Positive\"])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"../images/ModelDev_BaggedTrees_CM.png\")\n",
    "print(classification_report(val_y, pred_y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:03:19.608167Z",
     "end_time": "2023-04-12T01:03:19.927807Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Random Forest<a id=\"forest\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1. Hyperparamerters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": np.arange(1, 500, 20)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:03:19.905708Z",
     "end_time": "2023-04-12T01:03:19.927807Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2. Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    criterion=\"gini\",  # Good for balanced data (we have already up-sampled out data so it is now balanced)\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=0     # Reproducible result\n",
    ")\n",
    "\n",
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "pred_y = grid_clf.predict(val_X)\n",
    "# clf[\"forest\"] = grid_clf.best_estimator_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "sns.heatmap(confusion_matrix(val_y, pred_y), annot=True, cmap=\"Blues\", fmt=\"g\", ax=axis)\n",
    "axis.set_xlabel(\"Predicted Values\")\n",
    "axis.set_ylabel(\"True Values\")\n",
    "axis.set_title(\"Random Forest\")\n",
    "\n",
    "axis.set_xticks([0.5, 1.5])\n",
    "axis.set_xticklabels([\"Negative\", \"Positive\"])\n",
    "axis.set_yticks([0.5, 1.5])\n",
    "axis.set_yticklabels([\"Negative\", \"Positive\"])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"../images/ModelDev_RandomForest_CM.png\")\n",
    "print(classification_report(val_y, pred_y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T01:05:36.652274Z",
     "end_time": "2023-04-12T01:05:36.924186Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
