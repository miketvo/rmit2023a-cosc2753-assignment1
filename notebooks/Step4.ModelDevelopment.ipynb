{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4: Model Development\n",
    "\n",
    "---\n",
    "\n",
    "Appropriate machine learning algorithms for classification problems like ours includes:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- k-Nearest Neighbors\n",
    "- Support Vector Machine\n",
    "- Naive Bayes\n",
    "\n",
    "Considering the small number of samples in our dataset, the number of features, the binary nature of our problem, and the assignment constraints, we will develop and pick out the best algorithms among these 4:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Bagged Trees\n",
    "- Random Forest\n",
    "\n",
    "For individual model's performance evaluation, we will be using [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) to measure our models' performance and optimize them. While every sepsis case needs immediate attention, thus every potential sepsis patient needs close monitering, false positive predictions might take medical resources away from patients that might actually need it. In subsequent model development, if we see that recall and precision have different weights in our problem domain, we can switch to [F-beta](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html#:~:text=The%20F-beta%20score%20is,recall%20in%20the%20combined%20score.) instead.\n",
    "\n",
    "To get this performance, we will use K-Fold cross validation.\n",
    "\n",
    "For regularization, we will be using Grid Search method to select and fine tune our hyperparameters.\n",
    "\n",
    "To compare between the different model of different algorithms, we will use both $F_1$ score and [ROC-AUC](https://www.youtube.com/watch?v=4jRBRDbJemM). This will be done after we have developed our models.\n",
    "\n",
    "---\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "1. [Data Splitting](#data)\n",
    "2. [Logistic Regression](#logistic)\n",
    "3. [Decision Tree](#tree)\n",
    "4. [Bagged Trees](#bagged-trees)\n",
    "5. [Random Forest](#forest)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imports and environment setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "\n",
    "# Custom utils functions\n",
    "from utils.visualization import show_train_val_confusion_matrix\n",
    "from utils.visualization import visualize_training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:19.481223Z",
     "end_time": "2023-04-13T00:58:21.122546Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will store our developed models and their performance in the following variables:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clfs = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:21.124546Z",
     "end_time": "2023-04-13T00:58:21.129638Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Splitting<a id=\"data\"></a>\n",
    "\n",
    "For this section, we are using the processed datasets from [Step 3. Data Processing](Step3.DataProcessing.ipynb)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/processed_train.csv\")\n",
    "df_test = pd.read_csv(\"../data/processed_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:21.131639Z",
     "end_time": "2023-04-13T00:58:21.142688Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.info()\n",
    "df_test.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:21.143687Z",
     "end_time": "2023-04-13T00:58:21.204423Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:21.193564Z",
     "end_time": "2023-04-13T00:58:21.220722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separate our features (X) and target (y)\n",
    "df_X = df_train.drop([\"Sepsis\"], axis=1)\n",
    "df_y = df_train[[\"Sepsis\"]]\n",
    "\n",
    "# Splitting our training data into a train set and a validation set\n",
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "    df_X, df_y,\n",
    "    shuffle=True,\n",
    "    random_state=0,  # Ensure reproducible results\n",
    "    test_size=0.2    # 80% Train - 20% Validation\n",
    ")\n",
    "\n",
    "print(f\"train_X shape: {train_X.shape}\")\n",
    "print(f\"train_y shape: {train_y.shape}\")\n",
    "print(f\"val_X shape: {val_X.shape}\")\n",
    "print(f\"val_y shape: {val_y.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:21.223722Z",
     "end_time": "2023-04-13T00:58:21.229782Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up K-Fold cross validation for our models:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv = KFold(\n",
    "    n_splits=4,     # Each fold is 20% of df_X\n",
    "    shuffle=True,\n",
    "    random_state=0  # Reproducible result\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:21.231224Z",
     "end_time": "2023-04-13T00:58:21.233736Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Logistic Regression<a id=\"logistic\"></a>\n",
    "\n",
    "We would develop and evaluate the following models:\n",
    "\n",
    "- Logistic Regression with Linear Features;\n",
    "- Logistic Regression with Polynomial Features of degree 2;\n",
    "- Logistic Regression with Polynomial Features of degree 3;\n",
    "- Logistic Regression with Polynomial Features of degree 4.\n",
    "\n",
    "We are experimenting with both $L_1$ (lasso) and $L_2$ (ridge) regularization to find out which method is more appropriate. And although findings in [Step 1. EDA](Step1.EDA.ipynb) suggest that we stop at Polynomial Features of degree 3, we are still experimenting with degree 4 because we introduced regularization into our Logistic Regression model. However, we will not go any higher than degree 4, since it is too computationally expensive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    solver=\"liblinear\",       # Good for our small dataset\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1_000,\n",
    "    random_state=0            # Reproducible result\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:21.236502Z",
     "end_time": "2023-04-13T00:58:21.280231Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Hyperparameters\n",
    "\n",
    "- Regularization strength $\\lambda$ (lambda)\n",
    "- Regularization type: $L_1$ or $L_2$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"C\": 1 / np.logspace(-5, 2, num=100),\n",
    "    \"penalty\": [\"l1\", \"l2\"]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:21.242607Z",
     "end_time": "2023-04-13T00:58:21.280231Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Logistic Regression with Linear Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "train_pred_y = grid_clf.predict(train_X)\n",
    "val_pred_y = grid_clf.predict(val_X)\n",
    "clfs[\"logistic1\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:21.250654Z",
     "end_time": "2023-04-13T00:58:25.300483Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_training(clf, grid_clf, train_X, val_X, train_y, val_y, \"Training Evaluation\\nLogistic Regression - Linear\", \"../images/ModelDev_Logistic1_TrainValCompare.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:25.304559Z",
     "end_time": "2023-04-13T00:58:29.538668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_train_val_confusion_matrix(train_y, train_pred_y, val_y, val_pred_y, \"Model Performance\\nLogistic Regression - Linear\", \"../images/ModelDev_Logistic1_CM.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:29.541664Z",
     "end_time": "2023-04-13T00:58:30.059223Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3. Logistic Regression with 2nd Order Polynomial Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Degree 2 Polynomial Features:\n",
    "poly = PolynomialFeatures(2)\n",
    "train_X_poly2 = poly.fit_transform(train_X)\n",
    "val_X_poly2 = poly.transform(val_X)\n",
    "\n",
    "# We need to scale the data again after transforming it to polynomial features\n",
    "scaler = StandardScaler()\n",
    "train_X_poly2 = scaler.fit_transform(train_X_poly2)\n",
    "val_X_poly2 = scaler.transform(val_X_poly2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:30.062229Z",
     "end_time": "2023-04-13T00:58:30.070773Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X_poly2, train_y.values.ravel())\n",
    "\n",
    "train_pred_y = grid_clf.predict(train_X_poly2)\n",
    "val_pred_y = grid_clf.predict(val_X_poly2)\n",
    "clfs[\"logistic2\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:30.073774Z",
     "end_time": "2023-04-13T00:58:33.781545Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_training(clf, grid_clf, train_X, val_X, train_y, val_y, \"Training Evaluation\\nLogistic Regression - Polynomial 2\", \"../images/ModelDev_Logistic2_TrainValCompare.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:33.783806Z",
     "end_time": "2023-04-13T00:58:37.938771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_train_val_confusion_matrix(train_y, train_pred_y, val_y, val_pred_y, \"Model Performance\\nLogistic Regression - 2nd Order Polynomial\", \"../images/ModelDev_Logistic2_CM.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:37.964295Z",
     "end_time": "2023-04-13T00:58:38.464896Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4. Logistic Regression with 3rd Order Polynomial Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Degree 3 Polynomial Features:\n",
    "poly = PolynomialFeatures(3)\n",
    "train_X_poly3 = poly.fit_transform(train_X)\n",
    "val_X_poly3 = poly.transform(val_X)\n",
    "\n",
    "# We need to scale the data again after transforming it to polynomial features\n",
    "scaler = StandardScaler()\n",
    "train_X_poly3 = scaler.fit_transform(train_X_poly3)\n",
    "val_X_poly3 = scaler.transform(val_X_poly3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:38.464896Z",
     "end_time": "2023-04-13T00:58:38.501374Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X_poly3, train_y.values.ravel())\n",
    "\n",
    "train_pred_y = grid_clf.predict(train_X_poly3)\n",
    "val_pred_y = grid_clf.predict(val_X_poly3)\n",
    "clfs[\"logistic3\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:58:38.477346Z",
     "end_time": "2023-04-13T01:00:20.262772Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_training(clf, grid_clf, train_X, val_X, train_y, val_y, \"Training Evaluation\\nLogistic Regression - Polynomial 3\", \"../images/ModelDev_Logistic3_TrainValCompare.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:00:20.263772Z",
     "end_time": "2023-04-13T01:00:24.732975Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_train_val_confusion_matrix(train_y, train_pred_y, val_y, val_pred_y, \"Model Performance\\nLogistic Regression - 3rd Order Polynomial\", \"../images/ModelDev_Logistic3_CM.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:00:24.724947Z",
     "end_time": "2023-04-13T01:00:25.258897Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5. Logistic Regression with 4th Order Polynomial Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Degree 4 Polynomial Features:\n",
    "poly = PolynomialFeatures(4)\n",
    "train_X_poly4 = poly.fit_transform(train_X)\n",
    "val_X_poly4 = poly.transform(val_X)\n",
    "\n",
    "# We need to scale the data again after transforming it to polynomial features\n",
    "scaler = StandardScaler()\n",
    "train_X_poly4 = scaler.fit_transform(train_X_poly4)\n",
    "val_X_poly4 = scaler.transform(val_X_poly4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:00:25.256891Z",
     "end_time": "2023-04-13T01:00:25.274380Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X_poly4, train_y.values.ravel())\n",
    "\n",
    "train_pred_y = grid_clf.predict(train_X_poly4)\n",
    "val_pred_y = grid_clf.predict(val_X_poly4)\n",
    "clfs[\"logistic4\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:00:25.274380Z",
     "end_time": "2023-04-13T01:01:23.587159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_training(clf, grid_clf, train_X, val_X, train_y, val_y, \"Training Evaluation\\nLogistic Regression - Polynomial 4\", \"../images/ModelDev_Logistic4_TrainValCompare.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:01:23.589671Z",
     "end_time": "2023-04-13T01:01:27.877650Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_train_val_confusion_matrix(train_y, train_pred_y, val_y, val_pred_y, \"Model Performance\\nLogistic Regression - 4th Order Polynomial\", \"../images/ModelDev_Logistic4_CM.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:01:27.879158Z",
     "end_time": "2023-04-13T01:01:28.430048Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6. Observation\n",
    "\n",
    "All models seem to have good fit on the problem, however:\n",
    "\n",
    "- $L_1$ (Lasso) Regularization clearly is not a good choice for our problem, as the larger $\\lambda$ (lambda) grows, the worse our models' performance gets, regardless of which degree of polynomial feature it is. This is likely because we have only a few features, and all of them are significant, while Lasso Regularization tends to feature select.\n",
    "- Thus $L_2$ (Ridge) Regularization is more appropriate for our problem.\n",
    "- The best performing model is `clf_logistic4_l2`, in contrary to our hypothesis in [Step 1. EDA](Step1.EDA.ipynb), but this is because we have applied regularization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Decision Tree<a id=\"tree\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1. Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": np.arange(2, 300, 50),\n",
    "    \"min_samples_split\": np.arange(2, 50, 5),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:01:28.425049Z",
     "end_time": "2023-04-13T01:01:28.430048Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2. Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",         # Good for balanced data (we have already up-sampled out data so it is now balanced)\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=0            # Reproducible result\n",
    ")\n",
    "\n",
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "train_pred_y = grid_clf.predict(train_X)\n",
    "val_pred_y = grid_clf.predict(val_X)\n",
    "clfs[\"tree\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:01:28.428964Z",
     "end_time": "2023-04-13T01:01:29.800443Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_training(clf, grid_clf, train_X, val_X, train_y, val_y, \"Training Evaluation\\nDecision Tree\", \"../images/ModelDev_Tree_TrainValCompare.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:01:29.802643Z",
     "end_time": "2023-04-13T01:01:31.831562Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_train_val_confusion_matrix(train_y, train_pred_y, val_y, val_pred_y, \"Model Performance\\nDecision Tree\", \"../images/ModelDev_Tree_CM.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:01:31.834562Z",
     "end_time": "2023-04-13T01:01:32.335994Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Bagged Trees<a id=\"bagged-trees\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1. Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": np.arange(5, 25, 2),\n",
    "    \"max_samples\": np.arange(0.1, 1.0, 0.1),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T01:01:32.326666Z",
     "end_time": "2023-04-13T01:01:32.335994Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2. Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(\n",
    "    estimator=clfs[\"tree\"],\n",
    "    random_state=0  # Reproducible result\n",
    ")\n",
    "\n",
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "train_pred_y = grid_clf.predict(train_X)\n",
    "val_pred_y = grid_clf.predict(val_X)\n",
    "clfs[\"bagged_trees\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:50:00.667540Z",
     "end_time": "2023-04-13T00:50:14.435940Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_training(clf, grid_clf, train_X, val_X, train_y, val_y, \"Training Evaluation\\nBagged Trees\", \"../images/ModelDev_BaggedTrees_TrainValCompare.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:50:14.438963Z",
     "end_time": "2023-04-13T00:50:22.738536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_train_val_confusion_matrix(train_y, train_pred_y, val_y, val_pred_y, \"Model Performance\\nBagged Trees\", \"../images/ModelDev_BaggedTrees_CM.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:50:22.727555Z",
     "end_time": "2023-04-13T00:50:23.248598Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Random Forest<a id=\"forest\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1. Hyperparamerters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": np.arange(1, 500, 20),\n",
    "    \"max_depth\": np.arange(2, 300, 50)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:50:23.250594Z",
     "end_time": "2023-04-13T00:50:23.252341Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2. Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    criterion=\"gini\",  # Good for balanced data (we have already up-sampled out data so it is now balanced)\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=0     # Reproducible result\n",
    ")\n",
    "\n",
    "grid_clf = GridSearchCV(clf, params, cv=cv, scoring=\"f1\")\n",
    "grid_clf.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "train_pred_y = grid_clf.predict(train_X)\n",
    "val_pred_y = grid_clf.predict(val_X)\n",
    "clfs[\"forest\"] = grid_clf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:50:23.254355Z",
     "end_time": "2023-04-13T00:54:09.980407Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_training(clf, grid_clf, train_X, val_X, train_y, val_y, \"Training Evaluation\\nRandom Forest\", \"../images/ModelDev_RandomForest_TrainValCompare.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:54:09.981405Z",
     "end_time": "2023-04-13T00:56:02.480240Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_train_val_confusion_matrix(train_y, train_pred_y, val_y, val_pred_y, \"Model Performance\\nRandom Forest\", \"../images/ModelDev_RandomForest_CM.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T00:56:02.481746Z",
     "end_time": "2023-04-13T00:56:03.016385Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
